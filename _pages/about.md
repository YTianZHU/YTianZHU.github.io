---
permalink: /
title: "Tianzhu Ye 叶天竺"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About Me
I'm a first-year PhD student in Department of Automation at Tsinghua University, advised by [Gao Huang](https://www.gaohuang.net/). I also work as a research intern with Natural Language Computing group at Microsoft Research Asia, mentored by [Li Dong](https://dong.li/). My research focuses on building more capable and generalizable AI foundation models.

Email: ytz24@mails.tsinghua.edu.cn

Google Scholar: [GS](https://scholar.google.com/citations?user=7X8BCBsAAAAJ)

## Selected Publications

- <span style="color:#004B6B">Differential Transformer</span>  
**Tianzhu Ye**, Li Dong, Yuqing Xia, Yutao Sun, Yi Zhu, Gao Huang, Furu Wei  
*International Conference on Learning Representations (ICLR), 2025 (**Oral**)*  
[paper](https://arxiv.org/abs/2410.05258) | [code](https://aka.ms/Diff-Transformer)  

- <span style="color:#004B6B">Agent Attention: On the Integration of Softmax and Linear Attention</span>  
Dongchen Han, **Tianzhu Ye**, Yizeng Han, Zhuofan Xia, Siyuan Pan, Pengfei Wan, Shiji Song, Gao Huang  
*European Conference on Computer Vision (ECCV), 2024*  
[paper](https://arxiv.org/abs/2312.08874) | [code](https://github.com/LeapLabTHU/Agent-Attention)

- <span style="color:#004B6B">Slide-Transformer: Hierarchical Vision Transformer with Local Self-Attention</span>  
Xuran Pan, **Tianzhu Ye**, Zhuofan Xia, Shiji Song, Gao Huang  
*IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023*  
[paper](https://arxiv.org/abs/2304.04237) | [code](https://github.com/LeapLabTHU/Slide-Transformer)

## Education
- Ph.D. student, Tsinghua University (2024 - )
- Undergrauate student, Tsinghua University (2020 - 2024)

## Internship
- Research intern, Natural Language Computing group at Microsoft Research Asia, mentored by [Li Dong](https://dong.li/) (2023 - )
- Research intern, Megvii Technology (2022 - 2023)
